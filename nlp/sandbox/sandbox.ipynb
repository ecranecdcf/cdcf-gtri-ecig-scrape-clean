{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimental Sandbox\n",
        "\n",
        "This sandbox notebook is designed for **exploring, testing, and debugging** the NLP pipeline.\n",
        "Use the sections below to:\n",
        "- Verify project paths\n",
        "- Load modules dynamically\n",
        "- Run classification functions interactively\n",
        "- Experiment with data snippets\n",
        "- Prototype new prompts\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3833a2",
      "metadata": {},
      "source": [
        "### Importing packages and setting up NLP modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "### Add project root to sys.path for module imports\n",
        "import sys\n",
        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "NOTEBOOK_DIR = Path.cwd()\n",
        "\n",
        "NLP_ROOT = Path(PROJECT_ROOT)\n",
        "INGEST_DATA_DIR = NLP_ROOT / \"ingest\" / \"data\"\n",
        "OUTPUT_DIR = NLP_ROOT / \"output\"\n",
        "\n",
        "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"INGEST_DATA:\", INGEST_DATA_DIR)\n",
        "print(\"OUTPUT_DIR :\", OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now import via the full package path\n",
        "\n",
        "# Product features\n",
        "from process.regex.classify import classify_regex_df\n",
        "from process.product_type.classify import classify_product_category_df\n",
        "from process.cbd.classify import classify_cbd_df\n",
        "from process.tfn.classify import classify_tfn_df\n",
        "from process.flavor_extract.classify import extract_flavors_df\n",
        "from process.unit_count.classify import classify_unit_count_df\n",
        "# Flavor features\n",
        "from process.flavor_classify.classify import classify_flavor_df\n",
        "from process.other_flavor_classify.classify import classify_other_flavor_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c781827",
      "metadata": {},
      "source": [
        "### Core functions for use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### INITIALIZATION FUNCTIONS ###\n",
        "def load_dataset(filename: str, dtype=str) -> pd.DataFrame:\n",
        "    path = INGEST_DATA_DIR / filename\n",
        "    print(f\"Loading {path}\")\n",
        "    df = pd.read_csv(path, dtype=dtype)\n",
        "    print(\"Shape:\", df.shape)\n",
        "    return df\n",
        "\n",
        "def preview_df(df: pd.DataFrame, n: int = 5):\n",
        "    display(df.head(n))\n",
        "    print(\"\\nColumns:\\n\", df.columns.tolist())\n",
        "    print(\"\\nNull counts:\")\n",
        "    display(df.isna().sum().sort_values(ascending=False).head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39e98c0",
      "metadata": {},
      "source": [
        "#### We can classify the product pipeline or flavor pipeline using different datasets. Please adjust according to your needs and feel free to use a custom function!\n",
        "##### NOTE: Your custom function must be declared prior to running the cell below nad added to the sandbox_custom_pipeline function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### PROCESSING FUNCTIONS ###\n",
        "def sandbox_product_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"Initial shape:\", df.shape)\n",
        "    ### TODO: REMOVE ANY PROCESSING STEPS NOT NEEDED FOR TESTING ###\n",
        "    # df = classify_regex_df(df)\n",
        "    # df = classify_product_category_df(df)\n",
        "    # df = classify_cbd_df(df)\n",
        "    # df = classify_tfn_df(df)\n",
        "    df = extract_flavors_df(df)\n",
        "    print(\"Final shape:\", df.shape)\n",
        "    return df\n",
        "\n",
        "def sandbox_flavor_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"Initial shape:\", df.shape)\n",
        "    ### TODO: REMOVE ANY PROCESSING STEPS NOT NEEDED FOR TESTING ###\n",
        "    df = classify_flavor_df(df)\n",
        "    df = classify_other_flavor_df(df)\n",
        "    print(\"Final shape:\", df.shape)\n",
        "    return df\n",
        "\n",
        "def sandbox_custom_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"Initial shape:\", df.shape)\n",
        "    ### TODO: ADD CUSTOM PROCESSING STEPS HERE ###\n",
        "    print(\"Final shape:\", df.shape)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d036da5",
      "metadata": {},
      "source": [
        "### Set-up and run code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db1bf41a",
      "metadata": {},
      "source": [
        "#### PRODUCT ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAMPLE_PRODUCT_FILE = \"products.csv\" ### Replace with actual sample file name. \n",
        "product_df = load_dataset(SAMPLE_PRODUCT_FILE, dtype=str)\n",
        "preview_df(product_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7c7ad7",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_products = product_df.sample(n=20, random_state=42)\n",
        "preview_df(sample_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "product_df_processed = sandbox_product_pipeline(product_df.copy())\n",
        "display(product_df_processed.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1734021",
      "metadata": {},
      "outputs": [],
      "source": [
        "product_df_processed.to_csv(OUTPUT_DIR / \"sandbox_product_output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa2dc196",
      "metadata": {},
      "source": [
        "#### FLAVOR ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAMPLE_FLAVOR_FILE = \"sample_10_products_flavor.csv\"\n",
        "\n",
        "try:\n",
        "    flavor_df = load_dataset(SAMPLE_FLAVOR_FILE, dtype=str)\n",
        "    preview_df(flavor_df)\n",
        "    flavor_df_processed = sandbox_flavor_pipeline(flavor_df.copy())\n",
        "    display(flavor_df_processed.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Missing flavor file: {SAMPLE_FLAVOR_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "if 'product_df_processed' in globals():\n",
        "    out_path = OUTPUT_DIR / f\"sandbox_product_output_{ts}.csv\"\n",
        "    product_df_processed.to_csv(out_path, index=False)\n",
        "    print(\"Saved product output:\", out_path)\n",
        "\n",
        "if 'flavor_df_processed' in globals():\n",
        "    out_path = OUTPUT_DIR / f\"sandbox_flavor_output_{ts}.csv\"\n",
        "    flavor_df_processed.to_csv(out_path, index=False)\n",
        "    print(\"Saved flavor output:\", out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scratch Space\n",
        "\n",
        "Use extra cells below for ad-hoc regex tweaks, prompt prototypes, or row-level inspection. A template is provided for use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89dd5d39",
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROMPT SANDBOX — MODIFY THIS SECTION TO CHANGE MODEL BEHAVIOR\n",
        "# Tips:\n",
        "# - Edit instructions to adjust how strict/loose the classifier should be.\n",
        "# - Add or remove examples to influence how the model generalizes.\n",
        "# - Keep the JSON schema consistent so the parser doesn’t break.\n",
        "# - Use relevant data features (i.e. product_name, description) to give the model full context.\n",
        "\n",
        "custom_prompt = \"\"\"\n",
        "You are an expert vape-product materials classifier. Your job is to determine the primary **material** of a vape device based on its product name and description.\n",
        "\n",
        "### VALID MATERIAL CATEGORIES\n",
        "- METAL\n",
        "- GLASS\n",
        "- OTHER\n",
        "\n",
        "### CLASSIFICATION INSTRUCTIONS\n",
        "1. Choose *only one* of the material categories.\n",
        "2. Consider tank, body, housing, and main components.\n",
        "3. Use key signals such as:\n",
        "   - Metal: stainless steel, alloy, aluminum, titanium\n",
        "   - Glass: glass tank, Pyrex, clear glass chamber\n",
        "   - Other: plastic, silicone, unknown, disposable not specifying materials\n",
        "\n",
        "### EXAMPLE FORMAT\n",
        "### Example 1\n",
        "Product Name: \"Stainless Steel Pod System\"\n",
        "Description: \"Full metal body with refillable tank.\"\n",
        "Output:\n",
        "{\n",
        "  \"material\": \"METAL\",\n",
        "  \"confidence\": \"high\",\n",
        "  \"reasoning\": \"Contains 'stainless steel' and 'metal body', clear metal signals.\"\n",
        "}\n",
        "\n",
        "### Example 2\n",
        "Product Name: \"Glass Tank Cartridge\"\n",
        "Description: \"Clear Pyrex chamber for oils.\"\n",
        "Output:\n",
        "{\n",
        "  \"material\": \"GLASS\",\n",
        "  \"confidence\": \"high\",\n",
        "  \"reasoning\": \"Mentions 'glass' and 'Pyrex', strong glass indicators.\"\n",
        "}\n",
        "\n",
        "### OUTPUT FORMAT (MUST BE VALID JSON)\n",
        "{{\n",
        "    \"material\": \"METAL | GLASS | OTHER\",\n",
        "    \"confidence\": \"high\" | \"low\",\n",
        "    \"reasoning\": \"short explanation referencing key words\"\n",
        "}}\n",
        "\n",
        "### PRODUCT INFORMATION\n",
        "Product Name: \"{product_name}\"\n",
        "Description: \"{description}\"\n",
        "\n",
        "JSON Output:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1eb595",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, requests, pandas as pd\n",
        "import logging\n",
        "\n",
        "# Set up basic error logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "MODEL = \"llama3.1:8b\"  \n",
        "API_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "# Create the prompt for classification\n",
        "def create_prompt(product_name, description=\"\"):    \n",
        "    # TODO: Change prompt as desired\n",
        "    prompt = f\"\"\"\n",
        "        {custom_prompt.format(product_name=product_name, description=description)}\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def classify_prompt(product_name, description=\"\"):\n",
        "    prompt = create_prompt(product_name, description)\n",
        "    \n",
        "    data = {\n",
        "        \"model\": MODEL,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False,\n",
        "        \"format\": \"json\"  # Request structured output\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.post(API_URL, json=data, timeout=60)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        response_json = response.json()\n",
        "        raw_result = response_json.get(\"response\", \"{}\")\n",
        "        \n",
        "        # Clean markdown fences if Ollama adds them\n",
        "        if raw_result.startswith(\"```json\"):\n",
        "            raw_result = raw_result[7:]\n",
        "        if raw_result.endswith(\"```\"):\n",
        "            raw_result = raw_result[:-3]\n",
        "        \n",
        "        result_data = json.loads(raw_result.strip())\n",
        "        \n",
        "        return {\n",
        "            \"category\": result_data.get(\"category\", \"Error\"),\n",
        "            \"confidence\": result_data.get(\"confidence\", \"low\"),\n",
        "            \"reasoning\": result_data.get(\"reasoning\", \"No reasoning provided.\")\n",
        "        }\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        logging.error(f\"API request failed for '{product_name}': {e}\")\n",
        "        return {\"category\": \"Error\", \"confidence\": \"low\", \"reasoning\": str(e)}\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        logging.error(f\"Failed to parse JSON response for '{product_name}': {e}\")\n",
        "        logging.debug(f\"Raw response: {raw_result}\")\n",
        "        return {\"category\": \"Error\", \"confidence\": \"low\", \"reasoning\": \"Invalid JSON returned by model.\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error for '{product_name}': {e}\")\n",
        "        return {\"category\": \"Error\", \"confidence\": \"low\", \"reasoning\": str(e)}\n",
        "\n",
        "def classify_df(df, name_col=\"product_name\", description_col=\"description\"):\n",
        "    results = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        name = row.get(name_col, \"\")\n",
        "        desc = row.get(description_col, \"\")\n",
        "\n",
        "        output = classify_prompt(name, desc)\n",
        "        results.append(output)\n",
        "\n",
        "    result_df = pd.DataFrame(results)\n",
        "    return pd.concat([df.reset_index(drop=True), result_df], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f18b94e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the code on a sample dataframe\n",
        "product_df = load_dataset(SAMPLE_PRODUCT_FILE, dtype=str)\n",
        "labeled_df = classify_df(product_df)\n",
        "print(labeled_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cdcf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
